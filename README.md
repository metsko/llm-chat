# llm-chat
General LLM chat ui for local model usage
